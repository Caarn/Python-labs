{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f31ec6a5-ceb5-48f2-9ab7-98f79095f957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If gamma ray bursters are extragalactic, would absorption from the\n",
      "galaxy be expected?  How transparent is the galactic core to gamma\n",
      "rays?\n",
      "\n",
      "How much energy does a burster put out?  I know energy depends on\n",
      "distance, which is unknown.  An answer of the form _X_ ergs per\n",
      "megaparsec^2 is OK.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Yes a flotation tank, combined with floride breathing water(REF: the Abyss\n",
      "breathing solution I think).. also the right position of the astronaut and\n",
      "strapping you can probably get much more than 45gs in an accesloration..\n",
      "More like near 100g (or somewhat less)..\n",
      "\n",
      "Saw I book called the \"Time Master\" (I thjink that was the title) that had some\n",
      "ideas on how fast and all you could go..\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Исходные данные из 2 лаб.\n",
    "categories = ['alt.atheism', 'sci.space', 'soc.religion.christian']\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=24, categories=categories, remove=remove)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=24, categories=categories, remove=remove)\n",
    "print(twenty_train.data[3])\n",
    "print(twenty_test.data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e111c3f-0813-430c-a442-63dccebfa13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ann jackson ( ajackson @ cs.ubc.ca ) wrote on 5 may : i would like to submit the follow which help me enorm . if it ha alreadi been post , i apolog . it seem that dure the middl age , it wa customari for pastor to explain the triniti to their parishon by analog to water . water is water , but can exist in three form -- liquid , ice and vapor . thu it is possibl for one essenc to exist in three form . and recent , the pastor of my church drew an analog , which i also found use -- a woman is often perciev by other in three way , depend on their relationship to her -- a mother , a wife and an employe in a busi . thu , it seem clear to me that the essenc of god can subsist in the father , son , and holi spirit or , depend on one 's particular need for him .\n"
     ]
    }
   ],
   "source": [
    "# Применить стемминг\n",
    "def stemn(data):\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    stem = []\n",
    "    for text in data:\n",
    "        nltk_tokens = word_tokenize(text)\n",
    "        line = ''.join([' ' + porter_stemmer.stem(word) for word in nltk_tokens])\n",
    "        stem.append(line)\n",
    "    return stem\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "stem_train = []\n",
    "for text in twenty_train.data:\n",
    "    nltk_tokens = word_tokenize(text)\n",
    "    line = ''\n",
    "    for word in nltk_tokens:\n",
    "        line += ' ' + porter_stemmer.stem(word)\n",
    "    stem_train.append(line)\n",
    "print(stem_train[0])\n",
    "\n",
    "stem_test = stemn(twenty_test.data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = stem_train, stem_test, twenty_train.target, twenty_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "109cb395-7fd5-4827-a0b4-400c3ce5edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT\n",
    "dt_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', DecisionTreeClassifier()) \n",
    "])\n",
    "\n",
    "# Параметры для DT\n",
    "dt_param_grid = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "                 'tfidf__use_idf': (True, False),\n",
    "                 'clf__criterion': ['gini', 'entropy'],\n",
    "                 'clf__max_depth': list(range(1, 6)) + list(range(20, 101, 20))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcd7c8c5-201e-48a8-b9b6-b9e02119efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Параметры для KNN\n",
    "knn_param_grid = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "                  'tfidf__use_idf': (True, False),\n",
    "                  'clf__n_neighbors': [3, 5, 7],\n",
    "                  'clf__weights': ['uniform', 'distance'],\n",
    "                  'clf__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7cf51ce-4e2b-4bef-81ba-0c6d3a9de0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR\n",
    "lr_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Параметры для LR\n",
    "lr_param_grid = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "                 'tfidf__use_idf': (True, False),\n",
    "                 'clf__C': [0.1, 1, 10],\n",
    "                 'clf__solver': ['newton-cg', 'lbfgs', 'sag', 'liblinear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c603041-fbb1-4b5c-8def-4a8984e1c7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимизация параметров для DecisionTreeClassifier\n",
      "Лучшие параметры с использованием стемминга: {'clf__criterion': 'entropy', 'clf__max_depth': 20, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}\n",
      "Точность с использованием стемминга: 0.6300630063006301\n",
      "Точность с использованием стемминга: 0.6322007535660351\n",
      "Полнота с использованием стемминга: 0.6300630063006301\n",
      "F1-мера с использованием стемминга: 0.6281133499766839\n",
      "Лучшие параметры без стемминга: {'clf__criterion': 'gini', 'clf__max_depth': 60, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}\n",
      "Точность без стемминга: 0.6336633663366337\n",
      "Точность без стемминга: 0.6302850448994715\n",
      "Полнота без стемминга: 0.6336633663366337\n",
      "F1-мера без стемминга: 0.6312351029550983\n",
      "\n",
      "\n",
      "Оптимизация параметров для KNeighborsClassifier\n",
      "Лучшие параметры с использованием стемминга: {'clf__algorithm': 'auto', 'clf__n_neighbors': 7, 'clf__weights': 'distance', 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}\n",
      "Точность с использованием стемминга: 0.5418541854185418\n",
      "Точность с использованием стемминга: 0.5465711406305466\n",
      "Полнота с использованием стемминга: 0.5418541854185418\n",
      "F1-мера с использованием стемминга: 0.5276043688768739\n",
      "Лучшие параметры без стемминга: {'clf__algorithm': 'auto', 'clf__n_neighbors': 7, 'clf__weights': 'distance', 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}\n",
      "Точность без стемминга: 0.5085508550855086\n",
      "Точность без стемминга: 0.5106455194631043\n",
      "Полнота без стемминга: 0.5085508550855086\n",
      "F1-мера без стемминга: 0.49057782493916513\n",
      "\n",
      "\n",
      "Оптимизация параметров для LogisticRegression\n",
      "Лучшие параметры с использованием стемминга: {'clf__C': 10, 'clf__solver': 'newton-cg', 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n",
      "Точность с использованием стемминга: 0.8010801080108011\n",
      "Точность с использованием стемминга: 0.8038303968085118\n",
      "Полнота с использованием стемминга: 0.8010801080108011\n",
      "F1-мера с использованием стемминга: 0.7932276013975342\n",
      "Лучшие параметры без стемминга: {'clf__C': 0.1, 'clf__solver': 'liblinear', 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n",
      "Точность без стемминга: 0.7902790279027903\n",
      "Точность без стемминга: 0.7965297088928458\n",
      "Полнота без стемминга: 0.7902790279027903\n",
      "F1-мера без стемминга: 0.780617723253874\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Список параметров\n",
    "pipelines = [dt_pipeline, knn_pipeline, lr_pipeline]\n",
    "param_grids = [dt_param_grid, knn_param_grid, lr_param_grid]\n",
    "\n",
    "# Цикл \n",
    "for i, pipeline in enumerate(pipelines):\n",
    "    print(f\"Оптимизация параметров для {pipeline.named_steps['clf'].__class__.__name__}\")\n",
    "\n",
    "    # Данные со стеммингом\n",
    "    grid_search_stem = GridSearchCV(pipeline, param_grids[i], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search_stem.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Лучшие параметры с использованием стемминга:\", grid_search_stem.best_params_)\n",
    "    y_pred_stem = grid_search_stem.predict(X_test)\n",
    "    print(\"Точность с использованием стемминга:\", accuracy_score(y_test, y_pred_stem))\n",
    "    print(\"Точность с использованием стемминга:\", precision_score(y_test, y_pred_stem, average='weighted'))\n",
    "    print(\"Полнота с использованием стемминга:\", recall_score(y_test, y_pred_stem, average='weighted'))\n",
    "    print(\"F1-мера с использованием стемминга:\", f1_score(y_test, y_pred_stem, average='weighted'))\n",
    "\n",
    "    # Данные без стемминга\n",
    "    grid_search_no_stem = GridSearchCV(pipeline, param_grids[i], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search_no_stem.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "    print(\"Лучшие параметры без стемминга:\", grid_search_no_stem.best_params_)\n",
    "    y_pred_no_stem = grid_search_no_stem.predict(twenty_test.data)\n",
    "    print(\"Точность без стемминга:\", accuracy_score(twenty_test.target, y_pred_no_stem))\n",
    "    print(\"Точность без стемминга:\", precision_score(twenty_test.target, y_pred_no_stem, average='weighted'))\n",
    "    print(\"Полнота без стемминга:\", recall_score(twenty_test.target, y_pred_no_stem, average='weighted'))\n",
    "    print(\"F1-мера без стемминга:\", f1_score(twenty_test.target, y_pred_no_stem, average='weighted'))\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d3f95-51fd-49c0-a7ac-f0c2a67ea3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
